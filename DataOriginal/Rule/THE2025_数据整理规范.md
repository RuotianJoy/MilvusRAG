# THE2025大学排名数据整理规范

## 1. 数据概述

THE2025数据集包含世界顶尖大学的排名和详细信息，包括总体评分、教学质量、研究水平、引用指数、产业收入和国际化程度等多项指标。该规范旨在指导如何将原始JSON数据标准化，以便向量化并存储到Milvus向量数据库中。

## 2. 数据结构分析

### 2.1 核心字段说明

原始数据中的核心字段包括：

| 字段类别 | 字段名称 | 说明 |
|---------|---------|------|
| 排名信息 | rank_order | 排序序号 |
|         | rank | 显示排名 |
| 大学基本信息 | name | 大学名称 |
|           | location | 所在国家/地区 |
|           | aliases | 大学别名 |
|           | record_type | 记录类型(如private、master_account等) |
| 评分指标 | scores_overall | 总体评分 |
|         | scores_teaching | 教学评分 |
|         | scores_research | 研究评分 |
|         | scores_citations | 引用评分 |
|         | scores_industry_income | 产业收入评分 |
|         | scores_international_outlook | 国际化评分 |
| 统计数据 | stats_number_students | 学生数量 |
|         | stats_student_staff_ratio | 师生比例 |
|         | stats_pc_intl_students | 国际学生比例 |
|         | stats_female_male_ratio | 性别比例 |
| 学科信息 | subjects_offered | 提供的学科列表 |
| 其他信息 | url | 大学页面URL |
|         | nid | 唯一标识符 |

## 3. 数据预处理流程

### 3.1 数据清洗

1. **缺失值处理**:
   - 对于必要字段（name, rank, scores_overall等）的缺失值，标记为"未知"或适当默认值
   - 对于非必要字段的缺失值，可以填充为null或空字符串

2. **数据类型转换**:
   - 将所有评分字段转换为浮点数（如"98.5" → 98.5）
   - 将排名字段转换为整数（如"1" → 1）
   - 将百分比字段转换为浮点数（如"43%" → 0.43）

3. **文本标准化**:
   - 移除不必要的空格、标点符号
   - 统一文本大小写（如学校名称保持原格式，但在索引时不区分大小写）

### 3.2 数据结构化

1. **学科列表处理**:
   - 将subjects_offered字段从逗号分隔字符串转换为数组
   - 统一学科命名，确保相同学科有统一表示

2. **比例数据处理**:
   - 将stats_female_male_ratio从"51 : 49"格式转换为{female: 0.51, male: 0.49}结构

## 4. 向量化方法

### 4.1 文本向量化

1. **大学基本信息向量化**:
   - 将name、location和aliases字段组合，使用文本嵌入模型（如BERT或GPT系列）生成向量
   - 建议向量维度：768或1536（取决于所选模型）

2. **学科信息向量化**:
   - 将subjects_offered数组中的学科信息连接成文本，使用相同的嵌入模型生成向量

### 4.2 数值特征向量化

1. **评分指标向量化**:
   - 将所有scores_*字段组合成一个数值向量
   - 对数值进行归一化处理（如Min-Max缩放或Z-score标准化）

2. **统计数据向量化**:
   - 将stats_*字段组合成一个数值向量
   - 进行适当的归一化处理

## 5. Milvus存储方案

### 5.1 集合设计

创建名为`the2025_universities`的集合，包含以下字段：

```python
from pymilvus import Collection, FieldSchema, CollectionSchema, DataType

# 定义集合字段
fields = [
    FieldSchema(name="id", dtype=DataType.INT64, is_primary=True),
    FieldSchema(name="name", dtype=DataType.VARCHAR, max_length=256),
    FieldSchema(name="rank", dtype=DataType.INT64),
    FieldSchema(name="location", dtype=DataType.VARCHAR, max_length=128),
    FieldSchema(name="overall_score", dtype=DataType.FLOAT),
    FieldSchema(name="basic_info_vector", dtype=DataType.FLOAT_VECTOR, dim=1536),
    FieldSchema(name="subjects_vector", dtype=DataType.FLOAT_VECTOR, dim=1536),
    FieldSchema(name="metrics_vector", dtype=DataType.FLOAT_VECTOR, dim=10),
    FieldSchema(name="json_data", dtype=DataType.VARCHAR, max_length=65535)  # 存储原始JSON
]

# 创建集合模式
schema = CollectionSchema(fields, "THE2025大学排名数据集")

# 创建集合
collection = Collection("the2025_universities", schema)
```

### 5.2 索引设计

为向量字段创建索引：

```python
# 为基本信息向量创建索引
index_params = {
    "metric_type": "COSINE",  # 余弦相似度
    "index_type": "HNSW",     # 层次可导航小世界图索引
    "params": {"M": 16, "efConstruction": 200}
}
collection.create_index("basic_info_vector", index_params)

# 为学科向量创建索引
collection.create_index("subjects_vector", index_params)

# 为指标向量创建索引
collection.create_index("metrics_vector", {
    "metric_type": "L2",      # 欧几里得距离
    "index_type": "HNSW",
    "params": {"M": 16, "efConstruction": 200}
})
```

## 6. 数据导入流程

1. **数据预处理**:
   ```python
   def preprocess_university_data(raw_data):
       processed_data = {
           "id": raw_data.get("nid", 0),
           "name": raw_data.get("name", "Unknown"),
           "rank": int(raw_data.get("rank", 0)),
           "location": raw_data.get("location", "Unknown"),
           "overall_score": float(raw_data.get("scores_overall", 0)),
           "json_data": json.dumps(raw_data)
       }
       return processed_data
   ```

2. **向量生成**:
   ```python
   def generate_vectors(processed_data, model):
       # 基本信息向量
       basic_info_text = f"{processed_data['name']} {processed_data['location']}"
       basic_info_vector = model.encode(basic_info_text)
       
       # 解析并向量化学科信息
       subjects_text = raw_data.get("subjects_offered", "")
       subjects_vector = model.encode(subjects_text)
       
       # 指标向量
       scores = [
           float(raw_data.get("scores_teaching", 0)),
           float(raw_data.get("scores_research", 0)),
           float(raw_data.get("scores_citations", 0)),
           float(raw_data.get("scores_industry_income", 0)),
           float(raw_data.get("scores_international_outlook", 0))
       ]
       # 标准化评分
       metrics_vector = normalize_scores(scores)
       
       return basic_info_vector, subjects_vector, metrics_vector
   ```

3. **数据插入**:
   ```python
   def insert_to_milvus(collection, processed_data, vectors):
       basic_info_vector, subjects_vector, metrics_vector = vectors
       
       # 插入到Milvus
       collection.insert([
           processed_data["id"],
           processed_data["name"],
           processed_data["rank"],
           processed_data["location"],
           processed_data["overall_score"],
           basic_info_vector,
           subjects_vector,
           metrics_vector,
           processed_data["json_data"]
       ])
   ```

## 7. 查询示例

```python
# 按大学名称相似度搜索
def search_by_university_name(collection, query_text, model, top_k=5):
    query_vector = model.encode(query_text)
    search_params = {"metric_type": "COSINE", "params": {"ef": 100}}
    
    results = collection.search(
        data=[query_vector],
        anns_field="basic_info_vector",
        param=search_params,
        limit=top_k,
        output_fields=["name", "rank", "location", "overall_score"]
    )
    
    return results
    
# 按学科领域相似度搜索
def search_by_subject_area(collection, subject_query, model, top_k=5):
    query_vector = model.encode(subject_query)
    search_params = {"metric_type": "COSINE", "params": {"ef": 100}}
    
    results = collection.search(
        data=[query_vector],
        anns_field="subjects_vector",
        param=search_params,
        limit=top_k,
        output_fields=["name", "rank", "location", "subjects_offered"]
    )
    
    return results
```

## 8. 注意事项

1. 确保所有文本编码使用UTF-8格式
2. 定期更新向量模型以保持向量表示的准确性
3. 对于大规模数据，考虑批量处理以提高效率
4. 建立数据更新机制，确保新的排名数据能够及时添加到知识库中
5. 为提高检索效率，可考虑按地区或学科类别创建分区 